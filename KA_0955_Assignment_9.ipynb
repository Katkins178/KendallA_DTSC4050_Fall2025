{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katkins178/KendallA_DTSC4050_Fall2025/blob/main/KA_0955_Assignment_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 9\n",
        "\n",
        "Kendall Atkins\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "* Save a copy to your drive\n",
        "* Provide your name\n",
        "* Run the first code cell\n",
        "* Complete the rest of the cells given the prompt\n",
        "\n",
        "**Note**: There are three target variables. Only one is used in a code cell at a time."
      ],
      "metadata": {
        "id": "a8RuEXy0YGnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Methods"
      ],
      "metadata": {
        "id": "M_GIpdn-JqFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5mWXMl0w0WZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43fbd68-f851-4e71-b073-19098d22c234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1538654281\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.feature_selection import mutual_info_classif, chi2\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "\n",
        "def generate_user_seed():\n",
        "# Get current time in nanoseconds (more granular)\n",
        "    nanoseconds = time.time_ns()\n",
        "\n",
        "# Add a small random component to further reduce collision chances\n",
        "    random_component = random.randint(0, 1000)  # Adjust range as needed\n",
        "\n",
        "# Combine them (XOR is a good way to mix values)\n",
        "    seed = nanoseconds ^ random_component\n",
        "\n",
        "# Ensure the seed is within the valid range for numpy's seed\n",
        "    seed = seed % (2**32)  # Modulo to keep it within 32-bit range\n",
        "\n",
        "    return seed\n",
        "\n",
        "user_seed = generate_user_seed()\n",
        "print(user_seed)\n",
        "np.random.seed(user_seed)\n",
        "\n",
        "\n",
        "# Generate dataset\n",
        "n_samples = 500\n",
        "n_features = 10\n",
        "\n",
        "# Numerical features\n",
        "numerical_data = np.random.randn(n_samples, n_features - 2)  # 8 numerical features\n",
        "\n",
        "# Categorical features\n",
        "categorical_data = np.random.choice(['A', 'B', 'C', 'D'], size=(n_samples, 2))  # 2 categorical features\n",
        "\n",
        "# Create DataFrame\n",
        "columns_numerical = [f'num_{i}' for i in range(n_features - 2)]\n",
        "columns_categorical = ['cat_1', 'cat_2']\n",
        "df_numerical = pd.DataFrame(numerical_data, columns=columns_numerical)\n",
        "df_categorical = pd.DataFrame(categorical_data, columns=columns_categorical)\n",
        "\n",
        "df = pd.concat([df_numerical, df_categorical], axis=1)\n",
        "\n",
        "# Target variable (numerical and categorical for different methods)\n",
        "df['target_numerical'] = df['num_0'] + 0.5 * df['num_1'] + np.random.randn(n_samples) * 0.5\n",
        "df['target_categorical'] = np.random.choice(['Yes', 'No'], size=n_samples, p=[0.7, 0.3])\n",
        "\n",
        "# Create highly correlated features\n",
        "df['num_6'] = df['num_0'] + 0.8 * df['num_1'] + np.random.randn(n_samples) * 0.1  # Highly correlated with num_0 and num_1\n",
        "df['num_7'] = 0.7 * df['num_2'] - 0.9 * df['num_3'] + np.random.randn(n_samples) * 0.1  # Highly correlated with num_2 and num_3\n",
        "\n",
        "# Encode categorical target\n",
        "le = LabelEncoder()\n",
        "df['target_categorical_encoded'] = le.fit_transform(df['target_categorical'])\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = OrdinalEncoder()\n",
        "df[columns_categorical] = encoder.fit_transform(df[columns_categorical])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1a. Print the Pearson correlation coefficients between the columns_numerical and the target_numerical only\n",
        "pearson_corr = df[columns_numerical].corrwith(df[\"target_numerical\"])\n",
        "print(pearson_corr)"
      ],
      "metadata": {
        "id": "5dFqaZguCCmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40abb461-9c12-4668-aede-1a0bc55b3861"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_0    0.813522\n",
            "num_1    0.407011\n",
            "num_2    0.050437\n",
            "num_3    0.026618\n",
            "num_4    0.071344\n",
            "num_5    0.041500\n",
            "num_6    0.889647\n",
            "num_7    0.013619\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1b. What is the correlation between the columns_numerical and the target_numerical telling us?\n",
        "\n",
        "num_0 and num_6 have strong correlations. Most likely the true driver of the target\n",
        "num_1 has a moderate correlation\n",
        "the rest have weak to no correlations"
      ],
      "metadata": {
        "id": "OLXKF44xccBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2a. Print the feature and the Variance Inflation Factor (VIF) values for the numerical features only\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = df_numerical.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df_numerical.values, i) for i in range(len(df_numerical.columns))]\n",
        "print(vif_data.to_string(index=False))"
      ],
      "metadata": {
        "id": "HIHhuDVPCEzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28372fe3-2389-420b-e6a1-a097c704693a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature      VIF\n",
            "  num_0 1.014793\n",
            "  num_1 1.014504\n",
            "  num_2 1.013029\n",
            "  num_3 1.005749\n",
            "  num_4 1.015674\n",
            "  num_5 1.007460\n",
            "  num_6 1.003990\n",
            "  num_7 1.016054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2b. What is VIF telling us?\n",
        "\n",
        "Their is no multicolinierity among the features because the VIF is around 1 for all features"
      ],
      "metadata": {
        "id": "scdRVboccEYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3a. Print the Mutual Information Classification values between all features that start with num or cat and the categorical target encoded\n",
        "feature_cols = columns_numerical + columns_categorical\n",
        "X = df[feature_cols]\n",
        "y = df['target_categorical_encoded']\n",
        "\n",
        "mi_scores = mutual_info_classif(X, y, random_state=user_seed)\n",
        "\n",
        "mi_data = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'MI_Score': mi_scores\n",
        "})\n",
        "\n",
        "print(\"\\nMutual Information Classification Scores:\")\n",
        "print(mi_data.to_string(index=False))"
      ],
      "metadata": {
        "id": "jy7hp4BWCeQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded37609-181b-4e7c-cf7e-f9be5c16ed3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mutual Information Classification Scores:\n",
            "Feature  MI_Score\n",
            "  num_0  0.000000\n",
            "  num_1  0.010987\n",
            "  num_2  0.000000\n",
            "  num_3  0.000000\n",
            "  num_4  0.009639\n",
            "  num_5  0.047573\n",
            "  num_6  0.033834\n",
            "  num_7  0.008853\n",
            "  cat_1  0.000000\n",
            "  cat_2  0.017127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b. What are the mutual information values telling us?\n",
        "\n",
        "None of the features help predict the target as all values were around 0"
      ],
      "metadata": {
        "id": "BuX-vGERdVf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chi2_scores, p_values = chi2(df[columns_categorical], df['target_categorical_encoded'])\n",
        "chi2_data = pd.DataFrame({\n",
        "    'Feature': columns_categorical,\n",
        "    'Chi2_Score': chi2_scores,\n",
        "    'P_Value': p_values\n",
        "})\n",
        "print(\"\\nChi-Square Test Results:\")\n",
        "print(chi2_data.to_string(index=False))"
      ],
      "metadata": {
        "id": "mLcqXjbfG0F-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490db9d2-358c-4898-c087-4a7ac3e76c3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chi-Square Test Results:\n",
            "Feature  Chi2_Score  P_Value\n",
            "  cat_1    0.144973 0.703387\n",
            "  cat_2    0.071599 0.789023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4b. What are the Chi-Square values telling us?\n",
        "\n",
        "Because the Chi-square is much smaller than .05, there is no statistical relationship between the categorical feature and the target"
      ],
      "metadata": {
        "id": "ry31NGNMd9Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5a. Print the Variance Threshold values for the columns_numerical\n",
        "variances = df_numerical.var()\n",
        "\n",
        "variance_data = pd.DataFrame({\n",
        "    'Feature': columns_numerical,\n",
        "    'Variance': variances.values\n",
        "})\n",
        "\n",
        "print(\"\\nVariance Threshold Values:\")\n",
        "print(variance_data.to_string(index=False))"
      ],
      "metadata": {
        "id": "aQOUzgocG5H2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161c6c9a-9f4c-481a-eee5-fbd7363fe5ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Variance Threshold Values:\n",
            "Feature  Variance\n",
            "  num_0  1.037391\n",
            "  num_1  0.926036\n",
            "  num_2  0.986655\n",
            "  num_3  1.092006\n",
            "  num_4  0.959237\n",
            "  num_5  1.042099\n",
            "  num_6  0.971602\n",
            "  num_7  0.931579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5b. What is are the Variance Threshold values telling us?\n",
        "\n",
        "Each feature has a normal sized variation (1)"
      ],
      "metadata": {
        "id": "fPD35xLTeVan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the following code cell**"
      ],
      "metadata": {
        "id": "Pjosnl6dJ10S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X, y = make_regression(n_samples=200, n_features=10, n_informative=5, random_state=user_seed)\n",
        "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
        "X = pd.DataFrame(X, columns=feature_names)\n",
        "y = pd.Series(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=user_seed)\n",
        "print(user_seed)\n",
        "\n"
      ],
      "metadata": {
        "id": "MFO1x71uKM3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21079e4a-9b2a-43bb-dc10-e0b217422004"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1538654281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6a. Create a linear regression model and a RFE object, selecting the top 5 features.\n",
        "# Fit (train) the RFE model with X_train and y_train\n",
        "# Print the selected features and their rankings\n",
        "\n",
        "# Create RFE object to select top 5 features\n",
        "rfe = RFE(estimator= LinearRegression(), n_features_to_select=5)\n",
        "\n",
        "# Fit the RFE model\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfe.support_].tolist()\n",
        "\n",
        "# Get the feature rankings (1 = selected, higher numbers = eliminated earlier)\n",
        "feature_rankings = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Selected': rfe.support_,\n",
        "    'Ranking': rfe.ranking_\n",
        "}).sort_values('Ranking')\n",
        "\n",
        "print(\"Selected Features (Top 5):\")\n",
        "print(selected_features)\n",
        "print(\"\\nFeature Rankings:\")\n",
        "print(feature_rankings)\n",
        "print(\"\\nDetailed Ranking (1 = selected):\")\n",
        "for idx, row in feature_rankings.iterrows():\n",
        "    status = \"✓ SELECTED\" if row['Selected'] else \"✗ Eliminated\"\n",
        "    print(f\"{row['Feature']}: Rank {row['Ranking']} {status}\")"
      ],
      "metadata": {
        "id": "gwA1gH3KfJ7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52414d6-13f8-417d-cbdb-5e1c04790ed2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features (Top 5):\n",
            "['feature_0', 'feature_1', 'feature_3', 'feature_7', 'feature_8']\n",
            "\n",
            "Feature Rankings:\n",
            "     Feature  Selected  Ranking\n",
            "0  feature_0      True        1\n",
            "1  feature_1      True        1\n",
            "3  feature_3      True        1\n",
            "7  feature_7      True        1\n",
            "8  feature_8      True        1\n",
            "9  feature_9     False        2\n",
            "2  feature_2     False        3\n",
            "6  feature_6     False        4\n",
            "4  feature_4     False        5\n",
            "5  feature_5     False        6\n",
            "\n",
            "Detailed Ranking (1 = selected):\n",
            "feature_0: Rank 1 ✓ SELECTED\n",
            "feature_1: Rank 1 ✓ SELECTED\n",
            "feature_3: Rank 1 ✓ SELECTED\n",
            "feature_7: Rank 1 ✓ SELECTED\n",
            "feature_8: Rank 1 ✓ SELECTED\n",
            "feature_9: Rank 2 ✗ Eliminated\n",
            "feature_2: Rank 3 ✗ Eliminated\n",
            "feature_6: Rank 4 ✗ Eliminated\n",
            "feature_4: Rank 5 ✗ Eliminated\n",
            "feature_5: Rank 6 ✗ Eliminated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6b. What is Recursive Feature Elimination doing for us?\n",
        "\n",
        "Helps narrow down from 10 features to 5 to give us a simpler and better performing model\n"
      ],
      "metadata": {
        "id": "ASabug21funK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the following code cell**"
      ],
      "metadata": {
        "id": "eY-o5D4kLKz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X, y = make_regression(n_samples=200, n_features=10, n_informative=5, random_state=user_seed)\n",
        "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
        "X = pd.DataFrame(X, columns=feature_names)\n",
        "y = pd.Series(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=user_seed)\n",
        "print(user_seed)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "mKGGZiFVLNZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8cc4d42-d046-47ad-cff3-e22233d77ee6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1538654281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7a. Create a Lasso model with alpha = 0.1\n",
        "# Fit (train) the model with X_train_scaled and y_train\n",
        "# Print the selected features and coefficients (with their feature names)\n",
        "lasso = Lasso(alpha=0.1, random_state=42)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the selected features and coefficients\n",
        "print(\"Lasso Coefficients:\")\n",
        "for feature, coef in zip(feature_names, lasso.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "# Show which features were selected (non-zero coefficients)\n",
        "selected_features = [feature for feature, coef in zip(feature_names, lasso.coef_) if coef != 0]\n",
        "print(f\"\\nSelected features (non-zero coefficients): {selected_features}\")\n",
        "print(f\"Number of features selected: {len(selected_features)}\")"
      ],
      "metadata": {
        "id": "-go1hbJsLVkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed24035-e22e-48de-b749-f7820ce1a875"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Coefficients:\n",
            "feature_0: 23.6109\n",
            "feature_1: 34.5022\n",
            "feature_2: -0.0000\n",
            "feature_3: 2.1830\n",
            "feature_4: 0.0000\n",
            "feature_5: -0.0000\n",
            "feature_6: 0.0000\n",
            "feature_7: 71.0828\n",
            "feature_8: 13.5648\n",
            "feature_9: -0.0000\n",
            "\n",
            "Selected features (non-zero coefficients): ['feature_0', 'feature_1', 'feature_3', 'feature_7', 'feature_8']\n",
            "Number of features selected: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7b. What is the Lasso model doing for us?\n",
        "\n",
        "Removing features  and regularization to help the model generalize better to unseen data"
      ],
      "metadata": {
        "id": "ZGDRPnlng7Lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7c. Why aren't we scaling y_train?\n",
        "\n",
        "Lasso only effects coefficients/slopes not the target variable"
      ],
      "metadata": {
        "id": "zSs0ua-jhFjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8a. Create a Ridge model aith alpha = 0.5\n",
        "# Fit (train) the model with X_train_scaled and y_train\n",
        "# Print the selected features based on threshold and print the coefficients (with their feature names)\n",
        "ridge_model = Ridge(alpha=0.5, random_state=42)\n",
        "\n",
        "# Fit (train) the model with X_train_scaled and y_train\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the coefficients with their feature names\n",
        "print(\"Ridge Model Coefficients:\")\n",
        "print(\"-\" * 50)\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': ridge_model.coef_\n",
        "}).sort_values('Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(coefficients_df.to_string(index=False))\n",
        "print(f\"\\nIntercept: {ridge_model.intercept_:.4f}\")"
      ],
      "metadata": {
        "id": "AfzOQJcRLbiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8082076c-4445-4b20-97f4-9707bb675bd6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Model Coefficients:\n",
            "--------------------------------------------------\n",
            "  Feature  Coefficient\n",
            "feature_7    70.913710\n",
            "feature_1    34.463798\n",
            "feature_0    23.633995\n",
            "feature_8    13.626567\n",
            "feature_3     2.297274\n",
            "feature_5    -0.038610\n",
            "feature_6     0.025717\n",
            "feature_2    -0.012401\n",
            "feature_9    -0.004525\n",
            "feature_4    -0.000061\n",
            "\n",
            "Intercept: -1.1897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8b. What does the ridge model do for us?\n",
        "\n",
        "Penalizes large coefficients to create a simpler model and reduce overfitting"
      ],
      "metadata": {
        "id": "4UrUf9Zihqik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9a. Print the top 5 Select K Best Selected Features using f_regression\n",
        "selector = SelectKBest(score_func=f_regression, k=5)\n",
        "\n",
        "# Fit the selector on the training data\n",
        "selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the feature names and scores\n",
        "selected_features = [feature_names[i] for i in selected_indices]\n",
        "feature_scores = selector.scores_\n",
        "\n",
        "# Create a DataFrame with all features and their scores\n",
        "feature_scores_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'F-Score': feature_scores,\n",
        "    'Selected': ['Yes' if i in selected_indices else 'No' for i in range(len(feature_names))]\n",
        "}).sort_values('F-Score', ascending=False)\n",
        "\n",
        "print(\"Top 5 Features:\")\n",
        "print(feature_scores_df.head(5).to_string(index=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "hkO28C0TN7Og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c4aa37-7f2a-4f25-d503-19b9457fac86"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Features:\n",
            "  Feature    F-Score Selected\n",
            "feature_7 342.773887      Yes\n",
            "feature_1  24.073844      Yes\n",
            "feature_0  14.126981      Yes\n",
            "feature_8   5.128623      Yes\n",
            "feature_5   2.295739      Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9b. What does Select K Best do for us?\n",
        "Calculates F-statistic for each feacure then selects the k features with the highest F-scores/ stongest linear relationships."
      ],
      "metadata": {
        "id": "xuNdqIe_iCjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10a. Print the Selected Features with Select From Model (using RandomForestRegressor)\n",
        "\n",
        "# Create a RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on training data\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Create SelectFromModel using the trained RandomForest\n",
        "selector_model = SelectFromModel(rf_model, prefit=True)\n",
        "\n",
        "# Fit the SelectFromModel to set its internal attributes like threshold_\n",
        "selector_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_indices = selector_model.get_support(indices=True)\n",
        "\n",
        "# Get the feature names and importances\n",
        "selected_features = [feature_names[i] for i in selected_indices]\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame with all features and their importance scores\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances,\n",
        "    'Selected': ['Yes' if i in selected_indices else 'No' for i in range(len(feature_names))]\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nSelected Features:\")\n",
        "print(feature_importance_df[feature_importance_df['Selected'] == 'Yes'].to_string(index=False))\n"
      ],
      "metadata": {
        "id": "qZ5Cri_gN_uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c053f3ed-f510-4a83-c410-1e4c16f498d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected Features:\n",
            "  Feature  Importance Selected\n",
            "feature_7    0.742151      Yes\n",
            "feature_1    0.134233      Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10b. What does Select From Model do for us?\n",
        "Selects features based on the importance weights learned by the model, keeping onlt the most influential ones for predicting the target"
      ],
      "metadata": {
        "id": "tVf9HzwdiZAd"
      }
    }
  ]
}